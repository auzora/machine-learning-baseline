{"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"FBkA2Qt5O4zG","executionInfo":{"status":"ok","timestamp":1642786881690,"user_tz":-420,"elapsed":449,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"Lqyu1mpZO4zL"},"source":["\n","Tensors\n","==========================\n","\n","Tensors are a specialized data structure that are very similar to arrays and matrices.\n","In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n","\n","Tensors are similar to `NumPy’s <https://numpy.org/>`_ ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and\n","NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see `bridge-to-np-label`). Tensors\n","are also optimized for automatic differentiation (we'll see more about that later in the `Autograd <autogradqs_tutorial.html>`__\n","section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"T7x7v81qO4zP","executionInfo":{"status":"ok","timestamp":1642786882056,"user_tz":-420,"elapsed":32,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"L6ULq922O4zQ"},"source":["Initializing a Tensor\n","~~~~~~~~~~~~~~~~~~~~~\n","\n","Tensors can be initialized in various ways. Take a look at the following examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is automatically inferred.\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"FV1GK41jO4zS","executionInfo":{"status":"ok","timestamp":1642786882057,"user_tz":-420,"elapsed":32,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)"]},{"cell_type":"markdown","metadata":{"id":"CcIAlWQpO4zU"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"lcMVNSChO4zW","executionInfo":{"status":"ok","timestamp":1642786882068,"user_tz":-420,"elapsed":41,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"]},{"cell_type":"markdown","metadata":{"id":"N_feoh1bO4zZ"},"source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQHxhrPwO4zc","outputId":"34c9eece-fc58-48f5-ec49-d23fd3c63066","executionInfo":{"status":"ok","timestamp":1642786882069,"user_tz":-420,"elapsed":40,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.3414, 0.3392],\n","        [0.2706, 0.4589]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"iGv8PJB2O4zd"},"source":["**With random or constant values:**\n","\n","``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IP65L-K0O4ze","outputId":"d9ed6607-0b28-4d2d-b9b2-ceef9e179671","executionInfo":{"status":"ok","timestamp":1642786882070,"user_tz":-420,"elapsed":32,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.1268, 0.2905, 0.5815],\n","        [0.6578, 0.5625, 0.2417]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"cell_type":"markdown","metadata":{"id":"CRxk9HAAO4zg"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xzjZFD7yO4zh"},"source":["Attributes of a Tensor\n","~~~~~~~~~~~~~~~~~\n","\n","Tensor attributes describe their shape, datatype, and the device on which they are stored.\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9eyYB_uO4zh","outputId":"af1f425a-6c80-485a-9246-318df10572fa","executionInfo":{"status":"ok","timestamp":1642786882072,"user_tz":-420,"elapsed":29,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"uJCEVjXfO4zi"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hunMo2s_O4zj"},"source":["Operations on Tensors\n","~~~~~~~~~~~~~~~~~\n","\n","Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n","indexing, slicing), sampling and more are\n","comprehensively described `here <https://pytorch.org/docs/stable/torch.html>`__.\n","\n","Each of these operations can be run on the GPU (at typically higher speeds than on a\n","CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n","\n","By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n","``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"lR7FU1S_O4zk","executionInfo":{"status":"ok","timestamp":1642786882590,"user_tz":-420,"elapsed":108,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["# We move our tensor to the GPU if available\n","if torch.cuda.is_available():\n","    tensor = tensor.to('cuda')"]},{"cell_type":"markdown","metadata":{"id":"VmpnAN1yO4zl"},"source":["Try out some of the operations from the list.\n","If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tbjtUB7nO4zl"},"source":["**Standard numpy-like indexing and slicing:**\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPIyP3pWO4zm","outputId":"d47259ec-de69-44f1-ba4a-7b0d39762185","executionInfo":{"status":"ok","timestamp":1642786882592,"user_tz":-420,"elapsed":107,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["First row:  tensor([1., 1., 1., 1.])\n","First column:  tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print('First row: ', tensor[0])\n","print('First column: ', tensor[:, 0])\n","print('Last column:', tensor[..., -1])\n","tensor[:,1] = 0\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"ROYvWjyiO4zn"},"source":["**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n","See also `torch.stack <https://pytorch.org/docs/stable/generated/torch.stack.html>`__,\n","another tensor joining op that is subtly different from ``torch.cat``.\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNoP-3owO4zn","outputId":"a0986307-f3fd-4ebb-90df-3249d067a532","executionInfo":{"status":"ok","timestamp":1642786882594,"user_tz":-420,"elapsed":86,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"]},{"cell_type":"markdown","metadata":{"id":"IqfAHUAjO4zo"},"source":["**Arithmetic operations**\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOx19eUXO4zo","outputId":"9dadd953-85a0-4e36-e7dc-695c8e7e9be4","executionInfo":{"status":"ok","timestamp":1642786882596,"user_tz":-420,"elapsed":80,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"execution_count":28}],"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(tensor)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"cell_type":"markdown","metadata":{"id":"8ZLUagdYO4zp"},"source":["**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n","values of a tensor into one value, you can convert it to a Python\n","numerical value using ``item()``:\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wphSkaOIO4zp","outputId":"c4f15c17-0b5d-4889-8cd9-ddbe728cac0a","executionInfo":{"status":"ok","timestamp":1642786882597,"user_tz":-420,"elapsed":72,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"dal4hfiqO4zp"},"source":["**In-place operations**\n","Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n","For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-TfgwZmO4zq","outputId":"4c4d3adc-33f7-43a0-e557-e2f7666d41f1","executionInfo":{"status":"ok","timestamp":1642786882599,"user_tz":-420,"elapsed":65,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(tensor, \"\\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"aQW4Sq4gO4zq"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n","     of history. Hence, their use is discouraged.</p></div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"10njFD_HO4zq"},"source":["--------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"avgDmKW7O4zq"},"source":["\n","Bridge with NumPy\n","~~~~~~~~~~~~~~~~~\n","Tensors on the CPU and NumPy arrays can share their underlying memory\n","locations, and changing one will change\tthe other.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DdxOL82VO4zr"},"source":["Tensor to NumPy array\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZRPSmNJO4zr","outputId":"e6ae7bf9-39a4-48f2-f82f-b307f449125c","executionInfo":{"status":"ok","timestamp":1642786882602,"user_tz":-420,"elapsed":60,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"67olMSL_O4zr"},"source":["A change in the tensor reflects in the NumPy array.\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcCqJuwxO4zr","outputId":"4a9cdcb9-0d07-4847-b1b2-4bc50dd55ea4","executionInfo":{"status":"ok","timestamp":1642786882604,"user_tz":-420,"elapsed":53,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"tO-hdOF2O4zs"},"source":["NumPy array to Tensor\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"9SRe8M-QO4zs","executionInfo":{"status":"ok","timestamp":1642786882606,"user_tz":-420,"elapsed":47,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"markdown","metadata":{"id":"a8bJ-LwdO4zs"},"source":["Changes in the NumPy array reflects in the tensor.\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAzfb7XvO4zt","outputId":"ad742a58-c94b-4b7c-ef0d-9f1b3053bcaa","executionInfo":{"status":"ok","timestamp":1642786882608,"user_tz":-420,"elapsed":47,"user":{"displayName":"Dicky Luthfy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzEvaPHhZzNIpJGfoZ521UNWWPTwjA_5t8RFinyg=s64","userId":"04068377143818761488"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]}],"metadata":{"colab":{"name":"tensorqs_tutorial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":0}