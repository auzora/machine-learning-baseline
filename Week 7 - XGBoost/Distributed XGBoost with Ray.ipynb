{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed XGBoost with Ray.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOvBhvTw9oP9"
      },
      "source": [
        "**Installing and starting Ray**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhq8RK1l9eiC",
        "outputId": "5c27e13f-42be-45c5-db18-d7c2fa3936e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install ray"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.8.0-cp37-cp37m-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 35 kB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 599 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.41.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Installing collected packages: redis, ray\n",
            "Successfully installed ray-1.8.0 redis-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLw1XoyR9ygM"
      },
      "source": [
        "**Installing XGBoost-Ray**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1XmNmqI9vZP",
        "outputId": "2e251ed8-b088-4689-cb74-25fc132fc5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install xgboost_ray"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost_ray\n",
            "  Downloading xgboost_ray-0.1.5-py3-none-any.whl (136 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 122 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 136 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<5.0.0 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.1.5)\n",
            "Requirement already satisfied: ray>=1.6 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.8.0)\n",
            "Requirement already satisfied: numpy<1.20,>=1.16 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.13.3)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (0.90)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.17.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (2.6.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.41.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (21.2.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.3.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.5.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.13)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (7.1.2)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray>=1.6->xgboost_ray) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost>=0.90->xgboost_ray) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2.8.2)\n",
            "Installing collected packages: xgboost-ray\n",
            "Successfully installed xgboost-ray-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTTUKIU2917O"
      },
      "source": [
        "**Installing SKLearn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQnQXlOa94RQ",
        "outputId": "af7e387c-a2ca-4f0f-ac34-b470f11c05ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC6tU0aP96KR"
      },
      "source": [
        "**Simple training example**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZU04-h99JL",
        "outputId": "2262b21c-657b-45bc-830b-1ae888f585c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, train\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
        "train_set = RayDMatrix(train_x, train_y)\n",
        "\n",
        "evals_result = {}\n",
        "bst = train(\n",
        "    {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    },\n",
        "    train_set,\n",
        "    evals_result=evals_result,\n",
        "    evals=[(train_set, \"train\")],\n",
        "    verbose_eval=False,\n",
        "    ray_params=RayParams(num_actors=2, cpus_per_actor=1))\n",
        "\n",
        "bst.save_model(\"model.xgb\")\n",
        "print(\"Final training error: {:.4f}\".format(\n",
        "    evals_result[\"train\"][\"error\"][-1]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "  warnings.warn(LEGACY_WARNING)\n",
            "2021-11-13 01:27:34,253\tINFO main.py:971 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
            "2021-11-13 01:27:36,389\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
            "\u001b[2m\u001b[36m(pid=284)\u001b[0m [01:27:36] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=284)\u001b[0m [01:27:36] Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=308)\u001b[0m [01:27:36] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=308)\u001b[0m [01:27:36] Tree method is automatically selected to be 'approx' for distributed training.\n",
            "2021-11-13 01:27:37,977\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 4.58 seconds (1.58 pure XGBoost training time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training error: 0.0053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPB70Ge-Cqh"
      },
      "source": [
        "**Simple prediction example**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osoGceRl-E45",
        "outputId": "3613c77a-3d20-4f03-ec49-8c2159f5bba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, predict\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import xgboost as xgb\n",
        "\n",
        "data, labels = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "dpred = RayDMatrix(data, labels)\n",
        "\n",
        "bst = xgb.Booster(model_file=\"model.xgb\")\n",
        "pred_ray = predict(bst, dpred, ray_params=RayParams(num_actors=2))\n",
        "\n",
        "print(pred_ray)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "  warnings.warn(LEGACY_WARNING)\n",
            "2021-11-13 01:27:38,052\tINFO main.py:1535 -- [RayXGBoost] Created 2 remote actors.\n",
            "2021-11-13 01:27:40,396\tINFO main.py:1552 -- [RayXGBoost] Starting XGBoost prediction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07511145 0.04715708 0.02642454 0.11464816 0.08779665 0.19609766\n",
            " 0.02642454 0.03200296 0.03968306 0.06930447 0.09290799 0.02642454\n",
            " 0.03476055 0.05490047 0.05012454 0.02642454 0.03337562 0.02642454\n",
            " 0.02642454 0.9528658  0.9751126  0.9751126  0.07511145 0.02642454\n",
            " 0.02642454 0.04102892 0.03118352 0.02642454 0.02642454 0.08779665\n",
            " 0.02642454 0.03476055 0.02642454 0.02642454 0.02642454 0.02642454\n",
            " 0.0665335  0.9690314  0.33619487 0.0696831  0.5729184  0.15662025\n",
            " 0.03451282 0.03200296 0.12301622 0.04102892 0.9751126  0.04096693\n",
            " 0.97315884 0.9234187  0.9751126  0.9751126  0.9751126  0.03059936\n",
            " 0.09855346 0.9751126  0.02642454 0.03755146 0.9751126  0.97315884\n",
            " 0.9751126  0.97315884 0.02642454 0.9751126  0.03120249 0.03120249\n",
            " 0.97315884 0.9751126  0.8630876  0.9751126  0.02642454 0.9751126\n",
            " 0.02642454 0.18486539 0.9751126  0.02642454 0.9684864  0.07511145\n",
            " 0.04528174 0.9751126  0.97315884 0.8423582  0.02642454 0.02642454\n",
            " 0.9751126  0.02642454 0.18525673 0.02642454 0.9610139  0.91992867\n",
            " 0.9637276  0.07784454 0.9476124  0.9751126  0.02642454 0.02642454\n",
            " 0.9751126  0.9690314  0.97315884 0.04415701 0.10755398 0.97315884\n",
            " 0.9751126  0.97315884 0.9751126  0.07822353 0.9541412  0.9751126\n",
            " 0.03451282 0.97315884 0.97315884 0.9505852  0.8015017  0.9751126\n",
            " 0.97315884 0.97315884 0.9690314  0.02642454 0.02642454 0.03059936\n",
            " 0.97315884 0.02642454 0.03451282 0.93471986 0.9751126  0.9751126\n",
            " 0.08796025 0.03059936 0.89851445 0.02642454 0.97315884 0.02642454\n",
            " 0.03059936 0.8943731  0.03059936 0.83710206 0.9690314  0.9751126\n",
            " 0.04825843 0.9751126  0.9751126  0.06849893 0.9751126  0.9751126\n",
            " 0.9751126  0.97315884 0.14397003 0.9537103  0.8998925  0.9543276\n",
            " 0.9751126  0.97315884 0.911794   0.9751126  0.9622466  0.9751126\n",
            " 0.02642454 0.64313    0.9751126  0.9751126  0.95592535 0.08779665\n",
            " 0.02642454 0.97315884 0.02642454 0.9657479  0.97315884 0.03337562\n",
            " 0.02642454 0.9724673  0.9751126  0.0708931  0.07511145 0.9690314\n",
            " 0.96707124 0.9751126  0.9751126  0.02642454 0.95819813 0.9690314\n",
            " 0.02642454 0.02642454 0.03337562 0.9690314  0.09398807 0.97315884\n",
            " 0.03517583 0.9751126  0.9751126  0.9751126  0.04069214 0.77108157\n",
            " 0.9434622  0.08649345 0.02786062 0.9751126  0.03120249 0.07338996\n",
            " 0.02642454 0.03118352 0.97315884 0.02642454 0.02642454 0.02642454\n",
            " 0.9622466  0.21271785 0.9751126  0.06340088 0.8858816  0.8857505\n",
            " 0.02642454 0.9751126  0.08779665 0.04224477 0.03755146 0.04096693\n",
            " 0.96730274 0.9751126  0.02642454 0.02642454 0.9751126  0.9751126\n",
            " 0.9751126  0.02642454 0.9751126  0.92772865 0.9751126  0.95374286\n",
            " 0.9610139  0.0557286  0.02642454 0.94982344 0.94982344 0.02642454\n",
            " 0.97315884 0.9751126  0.02642454 0.02863778 0.90234286 0.02642454\n",
            " 0.9751126  0.9543276  0.96730274 0.9649017  0.02642454 0.97315884\n",
            " 0.9751126  0.9469942  0.93040526 0.9751126  0.03451282 0.9751126\n",
            " 0.02642454 0.02642454 0.02642454 0.11561671 0.02642454 0.031783\n",
            " 0.03476055 0.02786062 0.02642454 0.09290799 0.02642454 0.21080676\n",
            " 0.02642454 0.02642454 0.9751126  0.9751126  0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.02642454 0.97315884 0.04558344 0.8849121\n",
            " 0.9751126  0.03059936 0.96707124 0.9751126  0.02642454 0.9560918\n",
            " 0.02642454 0.04338858 0.9751126  0.9751126  0.96730274 0.9751126\n",
            " 0.9684864  0.9751126  0.8488096  0.7803997  0.9622466  0.9751126\n",
            " 0.9751126  0.9751126  0.9751126  0.5849058  0.92148197 0.9751126\n",
            " 0.02642454 0.9751126  0.02642454 0.9751126  0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.9683355  0.9751126  0.9751126  0.9548208\n",
            " 0.9751126  0.9751126  0.9751126  0.9690314  0.96707124 0.02642454\n",
            " 0.968825   0.9690314  0.9751126  0.04054494 0.9265608  0.02642454\n",
            " 0.9751126  0.9751126  0.9751126  0.9751126  0.02642454 0.05098807\n",
            " 0.031783   0.9751126  0.97315884 0.9751126  0.9751126  0.02642454\n",
            " 0.9751126  0.02642454 0.9751126  0.02642454 0.89866334 0.9751126\n",
            " 0.9751126  0.02642454 0.97315884 0.9751126  0.9751126  0.9203737\n",
            " 0.97315884 0.9751126  0.9751126  0.03451282 0.031783   0.02642454\n",
            " 0.9751126  0.9751126  0.9206134  0.9751126  0.95757306 0.9751126\n",
            " 0.96707124 0.9751126  0.9751126  0.7381298  0.9751126  0.02642454\n",
            " 0.02642454 0.9751126  0.02642454 0.02642454 0.02642454 0.9523307\n",
            " 0.04687763 0.031783   0.9751126  0.8943731  0.94464666 0.94982344\n",
            " 0.9751126  0.22631724 0.9487874  0.9751126  0.9751126  0.97315884\n",
            " 0.9751126  0.08594519 0.9751126  0.9751126  0.9751126  0.02642454\n",
            " 0.9751126  0.97315884 0.02642454 0.02642454 0.97315884 0.9751126\n",
            " 0.8689699  0.9690314  0.9751126  0.9751126  0.02642454 0.9751126\n",
            " 0.9751126  0.9543276  0.9751126  0.9751126  0.8515399  0.9350665\n",
            " 0.02642454 0.9751126  0.9251611  0.9751126  0.9751126  0.860673\n",
            " 0.1858404  0.97315884 0.97315884 0.02642454 0.9751126  0.9751126\n",
            " 0.9751126  0.8970261  0.9751126  0.9609949  0.893762   0.9751126\n",
            " 0.9751126  0.9751126  0.9751126  0.96707124 0.02786062 0.9622466\n",
            " 0.02642454 0.02642454 0.9724673  0.03678946 0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.95394206 0.02642454 0.9690314  0.9751126\n",
            " 0.04687763 0.94922996 0.02642454 0.9724673  0.9100143  0.02642454\n",
            " 0.9751126  0.02642454 0.94982344 0.9532535  0.9751126  0.9179891\n",
            " 0.935264   0.94982344 0.9751126  0.94982344 0.02642454 0.02642454\n",
            " 0.9751126  0.9751126  0.9751126  0.897271   0.96229064 0.9751126\n",
            " 0.02642454 0.9019002  0.9751126  0.9134064  0.87593234 0.94982344\n",
            " 0.9751126  0.9751126  0.81142044 0.9543276  0.9751126  0.031783\n",
            " 0.9751126  0.9476124  0.95515615 0.9543276  0.77870756 0.95053387\n",
            " 0.9548208  0.02642454 0.97315884 0.13313308 0.9751126  0.66283953\n",
            " 0.02642454 0.9751126  0.9751126  0.9008776  0.9407183  0.9751126\n",
            " 0.031783   0.02642454 0.9318961  0.04316882 0.9622466  0.02875218\n",
            " 0.9684864  0.9684864  0.9751126  0.97315884 0.9424551  0.02939261\n",
            " 0.9751126  0.96550983 0.03120249 0.93631655 0.1288219  0.9645091\n",
            " 0.02642454 0.02642454 0.9505852  0.9622466  0.97315884 0.02642454\n",
            " 0.9751126  0.9528658  0.97315884 0.97315884 0.93502516 0.9751126\n",
            " 0.950505   0.97315884 0.9751126  0.97315884 0.96634287 0.02642454\n",
            " 0.97315884 0.02642454 0.15464528 0.9293252  0.9751126  0.97315884\n",
            " 0.9751126  0.860673   0.94011134 0.9417494  0.9751126  0.9751126\n",
            " 0.9751126  0.97315884 0.9751126  0.9751126  0.9751126  0.9751126\n",
            " 0.94982344 0.9751126  0.94982344 0.88763565 0.9751126  0.94982344\n",
            " 0.9641301  0.88763565 0.92064005 0.9379563  0.02786062 0.02642454\n",
            " 0.02642454 0.02642454 0.03059936 0.02642454 0.9751126 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nzNfEas-Ic_"
      },
      "source": [
        "**Hyperparameter optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6rhpc3a-LHR",
        "outputId": "36b9fc41-caf5-4cf4-ef4a-ed2bd5343c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, train\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "num_actors = 1\n",
        "num_cpus_per_actor = 1\n",
        "\n",
        "ray_params = RayParams(\n",
        "    num_actors=num_actors, cpus_per_actor=num_cpus_per_actor)\n",
        "\n",
        "def train_model(config):\n",
        "    train_x, train_y = load_breast_cancer(return_X_y=True)\n",
        "    train_set = RayDMatrix(train_x, train_y)\n",
        "\n",
        "    evals_result = {}\n",
        "    bst = train(\n",
        "        params=config,\n",
        "        dtrain=train_set,\n",
        "        evals_result=evals_result,\n",
        "        evals=[(train_set, \"train\")],\n",
        "        verbose_eval=False,\n",
        "        ray_params=ray_params)\n",
        "    bst.save_model(\"model.xgb\")\n",
        "\n",
        "from ray import tune\n",
        "\n",
        "# Specify the hyperparameter search space.\n",
        "config = {\n",
        "    \"tree_method\": \"approx\",\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
        "    \"subsample\": tune.uniform(0.5, 1.0),\n",
        "    \"max_depth\": tune.randint(1, 9)\n",
        "}\n",
        "\n",
        "# Make sure to use the `get_tune_resources` method to set the `resources_per_trial`\n",
        "analysis = tune.run(\n",
        "    train_model,\n",
        "    config=config,\n",
        "    metric=\"train-error\",\n",
        "    mode=\"min\",\n",
        "    num_samples=4,\n",
        "    resources_per_trial=ray_params.get_tune_resources())\n",
        "print(\"Best hyperparameters\", analysis.best_config)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-13 01:27:40,509\tWARNING function_runner.py:564 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2021-11-13 01:27:40,532\tINFO logger.py:606 -- pip install 'ray[tune]' to see TensorBoard files.\n",
            "2021-11-13 01:27:40,535\tWARNING callback.py:115 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:27:40 (running for 00:00:00.15)<br>Memory usage on this node: 1.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td></tr>\n",
              "<tr><td>train_model_e486b_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td></tr>\n",
              "<tr><td>train_model_e486b_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td></tr>\n",
              "<tr><td>train_model_e486b_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m 2021-11-13 01:27:42,860\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m 2021-11-13 01:27:45,473\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:27:45 (running for 00:00:05.22)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00000</td><td>RUNNING </td><td>172.28.0.2:388</td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td></tr>\n",
              "<tr><td>train_model_e486b_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td></tr>\n",
              "<tr><td>train_model_e486b_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td></tr>\n",
              "<tr><td>train_model_e486b_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_e486b_00000:\n",
            "  date: 2021-11-13_01-27-46\n",
            "  done: false\n",
            "  experiment_id: 0e877a910b2e4f169fb0d8259fdaa038\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 388\n",
            "  time_since_restore: 3.7011101245880127\n",
            "  time_this_iter_s: 3.7011101245880127\n",
            "  time_total_s: 3.7011101245880127\n",
            "  timestamp: 1636766866\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.050967\n",
            "  train-logloss: 0.654491\n",
            "  training_iteration: 1\n",
            "  trial_id: e486b_00000\n",
            "  \n",
            "Result for train_model_e486b_00000:\n",
            "  date: 2021-11-13_01-27-46\n",
            "  done: true\n",
            "  experiment_id: 0e877a910b2e4f169fb0d8259fdaa038\n",
            "  experiment_tag: 0_eta=0.04731,max_depth=3,subsample=0.87771\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 388\n",
            "  time_since_restore: 3.776052236557007\n",
            "  time_this_iter_s: 0.006272792816162109\n",
            "  time_total_s: 3.776052236557007\n",
            "  timestamp: 1636766866\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.022847\n",
            "  train-logloss: 0.41105\n",
            "  training_iteration: 10\n",
            "  trial_id: e486b_00000\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=388)\u001b[0m 2021-11-13 01:27:46,597\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.79 seconds (1.12 pure XGBoost training time).\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-13 01:27:48,605\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-13 01:27:51,222\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:27:51 (running for 00:00:11.18)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: e486b_00000 with train-error=0.022847 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.04730998158914797, 'subsample': 0.8777108815517234, 'max_depth': 3, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (2 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00001</td><td>RUNNING   </td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00002</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00003</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00000</td><td>TERMINATED</td><td>172.28.0.2:388</td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77605</td><td style=\"text-align: right;\">        0.41105</td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_e486b_00001:\n",
            "  date: 2021-11-13_01-27-52\n",
            "  done: false\n",
            "  experiment_id: 3dc2d0145ca7411a90d5406dacf35390\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 494\n",
            "  time_since_restore: 3.7129874229431152\n",
            "  time_this_iter_s: 3.7129874229431152\n",
            "  time_total_s: 3.7129874229431152\n",
            "  timestamp: 1636766872\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.02812\n",
            "  train-logloss: 0.693016\n",
            "  training_iteration: 1\n",
            "  trial_id: e486b_00001\n",
            "  \n",
            "Result for train_model_e486b_00001:\n",
            "  date: 2021-11-13_01-27-52\n",
            "  done: true\n",
            "  experiment_id: 3dc2d0145ca7411a90d5406dacf35390\n",
            "  experiment_tag: 1_eta=0.00014431,max_depth=7,subsample=0.84818\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 494\n",
            "  time_since_restore: 3.7788326740264893\n",
            "  time_this_iter_s: 0.005101442337036133\n",
            "  time_total_s: 3.7788326740264893\n",
            "  timestamp: 1636766872\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.010545\n",
            "  train-logloss: 0.691882\n",
            "  training_iteration: 10\n",
            "  trial_id: e486b_00001\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-13 01:27:52,339\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.79 seconds (1.11 pure XGBoost training time).\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-13 01:27:54,322\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-13 01:27:56,937\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[1m\u001b[36m(scheduler +27s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:27:57 (running for 00:00:16.84)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: e486b_00001 with train-error=0.010545 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00014430696549007558, 'subsample': 0.848184273852242, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (1 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00002</td><td>RUNNING   </td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00003</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00000</td><td>TERMINATED</td><td>172.28.0.2:388</td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77605</td><td style=\"text-align: right;\">       0.41105 </td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "<tr><td>train_model_e486b_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77883</td><td style=\"text-align: right;\">       0.691882</td><td style=\"text-align: right;\">     0.010545</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_e486b_00002:\n",
            "  date: 2021-11-13_01-27-57\n",
            "  done: false\n",
            "  experiment_id: a0070000eb0840288ac08dbc03adfff4\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 598\n",
            "  time_since_restore: 3.7020065784454346\n",
            "  time_this_iter_s: 3.7020065784454346\n",
            "  time_total_s: 3.7020065784454346\n",
            "  timestamp: 1636766877\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.049209\n",
            "  train-logloss: 0.692135\n",
            "  training_iteration: 1\n",
            "  trial_id: e486b_00002\n",
            "  \n",
            "Result for train_model_e486b_00002:\n",
            "  date: 2021-11-13_01-27-58\n",
            "  done: true\n",
            "  experiment_id: a0070000eb0840288ac08dbc03adfff4\n",
            "  experiment_tag: 2_eta=0.0012056,max_depth=8,subsample=0.59122\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 598\n",
            "  time_since_restore: 3.7675912380218506\n",
            "  time_this_iter_s: 0.0051996707916259766\n",
            "  time_total_s: 3.7675912380218506\n",
            "  timestamp: 1636766878\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.02812\n",
            "  train-logloss: 0.683029\n",
            "  training_iteration: 10\n",
            "  trial_id: e486b_00002\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-13 01:27:58,058\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.78 seconds (1.12 pure XGBoost training time).\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m 2021-11-13 01:28:00,048\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m 2021-11-13 01:28:02,665\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:28:03 (running for 00:00:22.58)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: e486b_00001 with train-error=0.010545 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00014430696549007558, 'subsample': 0.848184273852242, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00003</td><td>RUNNING   </td><td>172.28.0.2:702</td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_e486b_00000</td><td>TERMINATED</td><td>172.28.0.2:388</td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77605</td><td style=\"text-align: right;\">       0.41105 </td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "<tr><td>train_model_e486b_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77883</td><td style=\"text-align: right;\">       0.691882</td><td style=\"text-align: right;\">     0.010545</td></tr>\n",
              "<tr><td>train_model_e486b_00002</td><td>TERMINATED</td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.76759</td><td style=\"text-align: right;\">       0.683029</td><td style=\"text-align: right;\">     0.02812 </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_e486b_00003:\n",
            "  date: 2021-11-13_01-28-03\n",
            "  done: false\n",
            "  experiment_id: 12d1cbb179f84a1fb1052a5af44f5976\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 702\n",
            "  time_since_restore: 3.710376739501953\n",
            "  time_this_iter_s: 3.710376739501953\n",
            "  time_total_s: 3.710376739501953\n",
            "  timestamp: 1636766883\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.038664\n",
            "  train-logloss: 0.664134\n",
            "  training_iteration: 1\n",
            "  trial_id: e486b_00003\n",
            "  \n",
            "Result for train_model_e486b_00003:\n",
            "  date: 2021-11-13_01-28-03\n",
            "  done: true\n",
            "  experiment_id: 12d1cbb179f84a1fb1052a5af44f5976\n",
            "  experiment_tag: 3_eta=0.034596,max_depth=4,subsample=0.75487\n",
            "  hostname: 1a8220ffa18b\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 702\n",
            "  time_since_restore: 3.7723660469055176\n",
            "  time_this_iter_s: 0.005841732025146484\n",
            "  time_total_s: 3.7723660469055176\n",
            "  timestamp: 1636766883\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.017575\n",
            "  train-logloss: 0.465689\n",
            "  training_iteration: 10\n",
            "  trial_id: e486b_00003\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=702)\u001b[0m 2021-11-13 01:28:03,786\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.79 seconds (1.12 pure XGBoost training time).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-13 01:28:03 (running for 00:00:23.28)<br>Memory usage on this node: 1.2/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: e486b_00001 with train-error=0.010545 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00014430696549007558, 'subsample': 0.848184273852242, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-13_01-27-40<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_e486b_00000</td><td>TERMINATED</td><td>172.28.0.2:388</td><td style=\"text-align: right;\">0.04731    </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.877711</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77605</td><td style=\"text-align: right;\">       0.41105 </td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "<tr><td>train_model_e486b_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.000144307</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.848184</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77883</td><td style=\"text-align: right;\">       0.691882</td><td style=\"text-align: right;\">     0.010545</td></tr>\n",
              "<tr><td>train_model_e486b_00002</td><td>TERMINATED</td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.00120555 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.591216</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.76759</td><td style=\"text-align: right;\">       0.683029</td><td style=\"text-align: right;\">     0.02812 </td></tr>\n",
              "<tr><td>train_model_e486b_00003</td><td>TERMINATED</td><td>172.28.0.2:702</td><td style=\"text-align: right;\">0.034596   </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">   0.754874</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77237</td><td style=\"text-align: right;\">       0.465689</td><td style=\"text-align: right;\">     0.017575</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-13 01:28:03,963\tINFO tune.py:630 -- Total run time: 23.46 seconds (23.27 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters {'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00014430696549007558, 'subsample': 0.848184273852242, 'max_depth': 7}\n"
          ]
        }
      ]
    }
  ]
}